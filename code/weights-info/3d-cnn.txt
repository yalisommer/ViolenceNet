in google drive: model_3dcnn_global_.94.h5, achieved 94% testing accuracy

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization, Input

def create_3d_cnn_model(input_shape=(16, 64, 64, 3), num_classes=2):
   model = Sequential()


   model.add(Input(shape=input_shape))


   model.add(Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu', padding='same'))
   model.add(MaxPooling3D(pool_size=(1, 2, 2)))  # Only spatial pooling
   model.add(BatchNormalization())


   model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu', padding='same'))
   model.add(MaxPooling3D(pool_size=(2, 2, 2)))
   model.add(BatchNormalization())


   model.add(Conv3D(filters=128, kernel_size=(3, 3, 3), activation='relu', padding='same'))
   model.add(MaxPooling3D(pool_size=(2, 2, 2)))
   model.add(BatchNormalization())


   #model.add(Flatten())
   model.add(GlobalAveragePooling3D())
   model.add(Dense(256, activation='relu'))
   model.add(Dropout(0.5))
   model.add(Dense(num_classes, activation='softmax'))


   model.summary()
   return model

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy


early_stopping_callback = EarlyStopping(
    monitor='val_accuracy',
    patience=25,
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.6,
    patience=5,
    min_lr=0.00005,
    verbose=1
)

model_3dcnn = create_3d_cnn_model()


model_3dcnn.compile(
    loss=CategoricalCrossentropy(label_smoothing=0.05),
    optimizer=Adam(learning_rate=0.0001),
    metrics=['accuracy']
)

history_3dcnn = model_3dcnn.fit(
    x=features_train,
    y=labels_train,
    epochs=60,
    batch_size=6,
    shuffle=True,
    validation_split=0.25,
    callbacks=[early_stopping_callback, reduce_lr]
)